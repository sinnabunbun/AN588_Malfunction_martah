---
title: "martah_FinalHomeworkCode_04"
author: "Marta"
date: "10/27/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Writing `z.prop.test`

I'm confused so I'm just going to write out what the z.prop.test function needs, breaking down into parameters, operations, and return:

### Parameters

-  <span style="color: purple;">p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data)</span>
  - so this would be just be our first variables of the argument with no additional arguments since they have no default: function(p1, n1)
  
-  <span style="color: purple;">p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test</span>
  - so two additional variables i would think but arguments of null F(p1, n1, p2=null, n2=null)

-  <span style="color: purple;">p0 (no default) as the expected value for the population proportion</span> 
  - again a variable with no argument f(p1, n1, p2=null, n2=null, p0)
  
-  <span style="color: purple;">alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().</span>
  - f(p1, n1, p2=null, n2=null, p0, alternative="t", conf.level=0.95)
  - this all makes sense since we are defining a new function- however, is there a specific argument i give these two to have them run the same?? i think they work fine without it, just wondering
  
#### _Parameters_
p1 <- estimated prop (and i'm assuming observed-this might be incorrect though)
n1 <- sample size
p2 <- estimated prop of second sample
n2 <- sample size of second sample
p0 <- expected prop (same as pi)
alternative & conf.interval <- same as t.test and fixed

### Operations
OK this is where it gets dicey, starting out I'm just looking over the one and two sample z test in mod 10. 
~general for of z test for proportions is:~

~z <- (observed statistic/__prportion__ - expected statistic/__prportion__) / standard error~

~where standard error is the sqrt of pi(1-pi)/n(umber of obsv) pi being expected proportion (p0) and observed prop is p1 so...~

~z <- (p0 - p1) / sqrt(p0(1-p0)/n1)~ Getting aheaD of myself here I moved this down to the one prop test where it beloNGS >:(

- <span style="color: purple;">When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().</span>
  - laundry list for 2: phat1 and phat2 as proportions of success given in args
  - pi as expected difference (usually 0)
  - pstar as pooled proportion
  - and n1 and n2 as number of observations
lets modify some things
- pstar <- (sum(v1) + sum(v2))/(length(v1) + length(v2))
instead we will sub out sum(v1) for our parameter p1 and same for sum(v2). length will also be given by our parameter n1 and n2 soooo...
> pstar<- (p1 + p2)/n1 + n2)

and for z we have 
> z <- (p1 - p2)/sqrt((pstar * (1 - pstar)) * ((1/n1) + (1/n2)))

for the actual p value we have this function
`p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)`
> p <- (1 - pnorm(z, lower.tail=true) + pnorm(z, lower.tail=false))

- For the other alternatives are we supposed to create a way to run the function if `alternative` does not equal two.sided? If so how? are we just adding more if arguments? do those p-value functions look different? I think we would just be splitting up the operations of my current `p` functions

-  <span style="color: purple;">The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.</span>
  - I think the best way would be putting the two prop first and including `if p1=null`. then we can use the operation `else` to run one prop test
  - _from the top of the page_
general for of z test for proportions is:

> z <- (observed statistic/__prportion__ - expected statistic/__prportion__) / standard error

where standard error is the sqrt of pi(1-pi)/n(umber of obsv) pi being expected proportion (p0) and observed prop is p1 so...
z <- (p1 - p0)/sqrt(p0 * (1 - p0)/n1)

-  <span style="color: purple;">The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.</span>
  - i really don't understand how to add this? i think i'm just going to throw it in the end as `rot<-n1*p1` and `rotb<-n1*(1-p1)` but the if less than 5 thing is confusing, the end would be `warning("this is bad") __thank you google for this and for the syntax that | means or in R___  
  - ok we might have it actually i think `rot|rotb < 5`

### Return

-  <span style="color: purple;">The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.</span>
  - return( list(z, p, ci))

### The Function

```{r z_function}
z.prop.test<- function(p1, n1, p2=NULL, n2=NULL, p0, alternative="t", conf.level=0.95){
#ONE PROP TEST
 if (is.null(p2)) { #i was trying to write two sided first but i can't figure out the how to command that without first defining one sided and then running else? #also this is just a cool thing, originally i had `if (p2 == NULL)` but r specifically switched it to `is.null`
   z <- (p1 - p0)/sqrt(p0 * (1 - p0)/n1) #z value
   p <- (1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)) #p value
     rot <- n1*p1
     rotb <- 1*(1-p1)
    if (rot|rotb < 5) {
    warning("Uhhhhhh think again.") #is this an appropriate response
  }
   lower <- p1 - qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
  upper <- p1 + qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
  ci <- c(lower, upper)
  one.prop.values <- list(z.test.statistic = as.numeric(z), p.value = as.numeric(p), confidence.intervals.as.defined.by.conf.level = as.numeric(ci))
return(one.prop.values)
 }
#TWO PROP TEST 
  else {
    pstar<- (p1 + p2)/(n1 + n2)
   z <- (p1 - p2)/sqrt((pstar * (1 - pstar)) * ((1/n1) + (1/n2))) #z value for 2
  p <- (1 - pnorm(z, lower.tail = T) + pnorm(z, lower.tail = F)) #p value same as before?
      rot <- n1*p1
     rotb <- 1*(1-p1)
     rot_ <- n2*p2
     rotb_ <- 1*(1-p2)
  if (rot|rot_|rotb|rotb_ < 5) {
    warning("Uhhhhhh think again.")
    }
   upper <- (p1 - p2) + (z * sqrt((p1*(1-p1)/n1) + (p2 * (1-p2)/n2)))
  lower <- (p1 - p2) - (z * sqrt((p1*(1-p1)/n1) + (p2 * (1-p2)/n2)))
  ci <- c(lower, upper)
  two.prop.values <- list(z.test.statistic = as.numeric(z), p.value = as.numeric(p), confidence.intervals.as.defined.by.conf.level = as.numeric(ci))
return(two.prop.values)
  }
}
```

## Testing `z.prop.test`
```{r testing}
z.prop.test(p1 = .5, n1 = 40, p0 = .6) #i have no idea how to pick values for this
z.prop.test(p1 = .8, n1 = 5, p0 = .6) #this should have set off my warning :/
z.prop.test(p1 = .6, n1 = 30, p0 = .8)
z.prop.test(p1 = .56, n1 = 25, p2 = .7, n2 = 30, p0 = 0)
```

## Regression

<span style="color: purple;">The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):</span>
  - MaxLongevity_m~Brain_Size_Species_Mean

``` {r new dataaaa}
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv")
monkeys <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
monkeys <- na.omit(monkeys)
head(monkeys)
```
oooooo, ahhhhhh

- <span style="color: purple;">Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).</span>

```{r regression dump}
m <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = monkeys)
summary(m)
ci1 <- confint(m, level = 0.90)
ci1
ci2 <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = monkeys$Brain_Size_Species_Mean), interval = "confidence",
    level = 0.90)
head(ci2)
lines <- data.frame(ci2)
```

```{r scatter for normal}
library(ggplot2)
monkey_graph <- ggplot(monkeys, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))   + 
  geom_point() +    
  geom_line(aes(x = monkeys$Brain_Size_Species_Mean, y = lines$fit), col = "orange") +
  geom_line(aes(x = monkeys$Brain_Size_Species_Mean, y = lines$upr), col = "purple") +
  geom_line(aes(x = monkeys$Brain_Size_Species_Mean, y = lines$lwr), col = "purple") +
  scale_colour_discrete(name = "Legend", labels = c("Fit", "Lwr", "Upr")) +
  labs(title = "logevity~brain size regression")
monkey_graph
```
```{r regression for logs}
logm <- lm(log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean), data = monkeys)
summary(logm)
logci1 <- confint(logm, level = 0.90)
logci1
```

```{r scatter for log}
library(ggplot2)
monkey_log_graph <- ggplot(monkeys, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m))) + 
  geom_point() +    
  geom_line(aes(x = log(monkeys$Brain_Size_Species_Mean), y = log(lines$fit), col = "orange")) +
  geom_line(aes(x = log(monkeys$Brain_Size_Species_Mean), y = log(lines$upr), col = "purple")) +
  geom_line(aes(x = log(monkeys$Brain_Size_Species_Mean), y = log(lines$lwr), col = "purple")) +
  labs(title = "log(logevity) ~ log(brain size regression)")
monkey_log_graph
```

- <span style="color: purple;">Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.</span>

- <span style="color: purple;">Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.</span>

- <span style="color: purple;">Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?</span>

```{r point estimate}
log.pt.est <- predict(logm, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction", 
    level = 0.90)  # for a single value
log.pt.est
```
- <span style="color: purple;">Looking at your two models, which do you think is better? Why?</span>
  - I'm struggling with the regression right now, but rn I think that the log data is more insightful because it is less spread out than the normal data. this makes it easier to see the trend line.


##Challenges

1. The pi always trips me up because I'm expecting it to be the constant pi and not a variable. That plus keeping track of the variables between the homework and the module i was using for help was confusing, I think I'm going to start using little tables like the one in the _parameters_ section to keep track of this stuff  
2. The p value test were confusing because i think the question is asking for if the alternative is set to greater or less as well as two sided which i think we could do if we split up the two sided tail arguments (i have no idea if that makes sense). if we did, would we have to do another if argument in the if argument setting the one and two prop tests apart??  
3. The CIs are still messing me up, i'm not sure which form to use and also i'm unsure how to account for the two prop test since all the CI functions we've had so far are one sample. In the return instructions it says include p2-p1 so i'm going to try substituting that in?  
4. My CI return is `numeric(0)` idk what that means or how to fix it? Google says its from calling something in the zeroth position but I'm just calling the CIs i calculated?   
5. Yikes the regression modeling went way over my head. The ggplot is still making sense but figuring out how to fit the regression model is tough. I don't hink I understand the arguments of geom_text? From what I can tell from the internet its seems like i need a formula but when I try to plug in the lm regression it does not like that.